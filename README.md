## To Do

- [x] Choose a programming language
- [ ] Choose a model
- [ ] Decide where to train and store data
- [x] Data scraping
- [x] Feature extraction
- [ ] Data pre-processing
- [ ] Model training
- [ ] Model evaluation
- [ ] Report writing
- [ ] Deployment

# Project Objective

1. Collect code samples from public code repositories.
2. Run static analysis to extract metrics.
3. Detect code smells and annotate quality levels.
4. Engineer features fro code structure and static metrics.
5. Train ML model(s) for overall quality prediction.
6. Evaluate model(s) performance and accuracy.
7. Provide insights and improvement suggestions based on predictions.

# Pipeline

```txt
scraper.py -> analyzer.py -> dataset_builder.py -> training -> evaluating
```

# Data Collection

## Languages used

- Python
- Java
- C++

## Sources

- Github
- ~Gitlab~

## Scraping

1. `scraper.py` queries Github REST API to find repositories and stores metadata (URL, Lanaguage, etc...).
2. `metadata_collector.py` extracts repo metadata and stores it `/data/metadata.json`.
3. `downloader.py` clones repos (using git) and stores them as raw data using a list generated by the scraper `/data/raw/temp/`.
4. `file_extractor.py` extracts relevant source code files `/data/raw/{repo_name}/{language}/{file_name}`.

# Feature Extraction

1. Send code files through `analyzer.py` that acts like a dispatcher for selecting the correct analyzer.
2. `analyzer.py` sends code to the correct analyzer, e.g., `python_analyzer.py`.
3. Analyzer output is sent to `metrics_extractor.py` for normalization and consistency.
4. `smell_detector.py` extracts and categorizes code smells.
5. `report_generator.py` generates structured JSON/CSV for dataset entry using all the previous steps `/data/processed/analysis_result/{repo_name}_{file_name}.json`.

# Feature Engineering

1. `feature_builder.py` builds complete feature sets (encoding, normalization, etc...) from the JSON data (outputs a CSV record).
2. `dataset_builder.py` creates the final dataset and saves it to `/data/processed/dataset.csv`

# Model(s) Design

Tree-based models will be used for detecting code smells.

## Target

- Code smells
- Overall code quality

## Algorithms

## Training Setup

## Metrics

## Example Evaluation Results

# Dependencies

# Reproducibility 

## Data Scrapping

## Static Analysis

## Feature Extraction

## Model Training

# Deployment

# Research References

