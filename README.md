## To Do

- [x] Choose a programming language
- [ ] Choose a model
- [ ] Decide where to train and store data
- [ ] Scrape the data
- [ ] Feature extraction
- [ ] Data pre-processing
- [ ] Model training
- [ ] Model evaluation
- [ ] Report writing
- [ ] Deployment

# Project Objective

1. Collect code samples from public code repositories.
2. Run static analysis to extract metrics.
3. Detect code smells and annotate quality levels.
4. Engineer features fro code structure and static metrics.
5. Train ML model(s) for overall quality prediction.
6. Evaluate model(s) performance and accuracy.
7. Provide insights and improvement suggestions based on predictions.

# Pipeline

# Data Collection

## Languages used

- Python
- Java
- C++

## Sources

- Github
- Gitlab

## Scraping

1. `scraper.py` queries Github REST API to find repositories and stores metadata (URL, Lanaguage, etc...).
2. `downloader.py` clones repos (using git) and stores them as raw data using a list generated by the scraper `/data/raw/temp/`.
3. `file_extractor.py` extracts relevant source code files `/data/raw/{repo_name}/{language}/{file_name}`.
4. `metadata_collector.py` extracts repo metadata and stores it `/data/metadata.json`.
5. `data_manager.py` handles local file organization (file storing, fetching, and naming for the previous steps).

# Feature Extraction

1. Send code files through `analyzer_factory.py` that acts like a dispatcher for selecting the correct analyzer.
2. `analyzer_factory.py` sends code to the correct analyzer, e.g., `python_analyzer.py`.
3. Analyzer output is sent to `metrics_extractor.py` for normalization and consistency.
4. `smell_detector.py` extracts and categorizes code smells.
5. `report_generator.py` generates structured JSON/CSV for dataset entry using all the previous steps `/data/processed/analysis_result/{repo_name}_{file_name}.json`.

# Feature Engineering

1. `feature_builder.py` builds complete feature sets from the JSON data (outputs a CSV record).
2. `dataset_builder.py` creates the final dataset and saves it to `/data/processed/dataset.csv`

# Model Design

## Target

## Algorithms

## Training Setup

## Metrics

## Example Evaluation Results

# Dependencies

# Reproducibility 

## Data Scrapping

## Static Analysis

## Feature Extraction

## Model Training

# Deployment

# Research References

