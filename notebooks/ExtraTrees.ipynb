{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4c8c66",
   "metadata": {},
   "source": [
    "# Extra Trees Model Training (from scraped GitHub code)\n",
    "\n",
    "This notebook trains an **Extra Trees** model on the metrics dataset produced by your pipeline.\n",
    "\n",
    "**Expected input:** `data/processed/dataset.csv` (built from analyzing code scraped from GitHub repos).\n",
    "\n",
    "**Output artifacts:** saved model + feature columns under `models/` (so you can reuse it for inference)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b88d54",
   "metadata": {},
   "source": [
    "## 1) Install dependencies (if needed)\n",
    "If you already have these installed, you can skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be689af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.4.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.8.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.8-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/omarh/Documents/GitHub/code-quality-assessment/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Using cached scipy-1.16.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.61.1-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/omarh/Documents/GitHub/code-quality-assessment/.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-12.0.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/omarh/Documents/GitHub/code-quality-assessment/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.3-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.3 MB)\n",
      "Downloading numpy-2.4.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m952.5 kB/s\u001b[0m  \u001b[33m0:00:17\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached scikit_learn-1.8.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached matplotlib-3.10.8-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.61.1-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "Using cached kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached pillow-12.0.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached scipy-1.16.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, cycler, scipy, pandas, contourpy, scikit-learn, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [matplotlib]5\u001b[0m [matplotlib]n]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 joblib-1.5.3 kiwisolver-1.4.9 matplotlib-3.10.8 numpy-2.4.0 pandas-2.3.3 pillow-12.0.0 pyparsing-3.3.1 pytz-2025.2 scikit-learn-1.8.0 scipy-1.16.3 threadpoolctl-3.6.0 tzdata-2025.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If running in a fresh environment, uncomment:\n",
    "%pip install -U pandas numpy scikit-learn joblib matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4755e",
   "metadata": {},
   "source": [
    "## 2) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41783a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: D:\\Gam3a\\CSCI417 Machine Intelligence\\Project\\code-quality-assessment\\data\\processed\\dataset_processed.csv\n",
      "Shape: (3088, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbreviation_density</th>\n",
       "      <th>average_cyclomatic_complexity</th>\n",
       "      <th>avg_line_length</th>\n",
       "      <th>comment_code_mismatch_score</th>\n",
       "      <th>comment_lines</th>\n",
       "      <th>comment_percentage</th>\n",
       "      <th>decision_density</th>\n",
       "      <th>documentation_coverage</th>\n",
       "      <th>external_vs_internal_field_access_ratio</th>\n",
       "      <th>functions</th>\n",
       "      <th>...</th>\n",
       "      <th>test_to_source_ratio</th>\n",
       "      <th>total_imports</th>\n",
       "      <th>y_binary</th>\n",
       "      <th>complexity_score</th>\n",
       "      <th>code_health</th>\n",
       "      <th>doc_quality</th>\n",
       "      <th>has_tests</th>\n",
       "      <th>coupling_complexity</th>\n",
       "      <th>smell_density</th>\n",
       "      <th>effort_impact_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.666324</td>\n",
       "      <td>0.568106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.623314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]</td>\n",
       "      <td>0.718428</td>\n",
       "      <td>0.880992</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.150928</td>\n",
       "      <td>0.449420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.306982</td>\n",
       "      <td>0.531561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.326629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.352370</td>\n",
       "      <td>0.932637</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.402474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.204312</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>0.300120</td>\n",
       "      <td>0.929269</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.551215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.204312</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.279220</td>\n",
       "      <td>0.932637</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.291447</td>\n",
       "      <td>0.019656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.204312</td>\n",
       "      <td>0.320598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.279220</td>\n",
       "      <td>0.932637</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.272644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abbreviation_density  average_cyclomatic_complexity  avg_line_length  \\\n",
       "0                 0.000                       0.666324         0.568106   \n",
       "1                 0.000                       0.306982         0.531561   \n",
       "2                 0.333                       0.204312         0.348837   \n",
       "3                 0.500                       0.204312         0.325581   \n",
       "4                 0.500                       0.204312         0.320598   \n",
       "\n",
       "   comment_code_mismatch_score  comment_lines  comment_percentage  \\\n",
       "0                          0.0           1.00                 1.0   \n",
       "1                          0.0           0.25                 1.0   \n",
       "2                          0.0           0.00                 0.0   \n",
       "3                          0.0           0.00                 0.0   \n",
       "4                          0.0           0.00                 0.0   \n",
       "\n",
       "   decision_density  documentation_coverage  \\\n",
       "0          0.623314                     0.0   \n",
       "1          0.326629                     0.0   \n",
       "2          0.163200                     0.0   \n",
       "3          0.104000                     0.0   \n",
       "4          0.099429                     0.0   \n",
       "\n",
       "   external_vs_internal_field_access_ratio  functions  ...  \\\n",
       "0                                 0.458333     0.1250  ...   \n",
       "1                                 0.125000     0.0625  ...   \n",
       "2                                 0.041667     0.0000  ...   \n",
       "3                                 0.041667     0.0000  ...   \n",
       "4                                 0.041667     0.0000  ...   \n",
       "\n",
       "   test_to_source_ratio  total_imports  \\\n",
       "0                   0.0       0.000000   \n",
       "1                   1.0       0.230769   \n",
       "2                   0.0       0.230769   \n",
       "3                   0.0       0.230769   \n",
       "4                   0.0       0.307692   \n",
       "\n",
       "                                  y_binary  complexity_score  code_health  \\\n",
       "0  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]          0.718428     0.880992   \n",
       "1  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]          0.352370     0.932637   \n",
       "2  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]          0.300120     0.929269   \n",
       "3  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]          0.279220     0.932637   \n",
       "4  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]          0.279220     0.932637   \n",
       "\n",
       "   doc_quality  has_tests  coupling_complexity  smell_density  \\\n",
       "0       0.4165          0             0.541667       0.150928   \n",
       "1       0.4525          1             0.083333       0.402474   \n",
       "2       0.5000          0             0.083333       0.551215   \n",
       "3       0.5000          0             0.083333       0.291447   \n",
       "4       0.5000          0             0.083333       0.272644   \n",
       "\n",
       "   effort_impact_ratio  \n",
       "0             0.449420  \n",
       "1             0.000000  \n",
       "2             0.000000  \n",
       "3             0.019656  \n",
       "4             0.000000  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns:\n",
      "['abbreviation_density', 'average_cyclomatic_complexity', 'avg_line_length', 'comment_code_mismatch_score', 'comment_lines', 'comment_percentage', 'decision_density', 'documentation_coverage', 'external_vs_internal_field_access_ratio', 'functions', 'global_usages_total', 'globals_declared', 'halstead_difficulty', 'halstead_effort', 'halstead_estimated_bugs', 'halstead_volume', 'inter_file_coupling', 'large_parameter_list_indicator', 'lazy_class_indicator', 'lines_added', 'lines_of_code', 'long_method_indicator', 'maintainability_score', 'max_cyclomatic_ratio', 'max_line_length', 'max_lines_per_function', 'max_nesting_level', 'mean_cyclomatic_ratio', 'mean_lines_per_function', 'mean_param_entropy', 'nesting_variance', 'percent_lines_over_80', 'source_lines', 'test_files_found', 'test_function_count', 'test_lines', 'test_to_source_ratio', 'total_imports', 'y_binary', 'complexity_score', 'code_health', 'doc_quality', 'has_tests', 'coupling_complexity', 'smell_density', 'effort_impact_ratio']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent  # notebooks/ -> repo root\n",
    "DATASET_PATH = PROJECT_ROOT / 'data' / 'processed' / 'dataset_processed.csv'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATASET_PATH.exists():\n",
    "    raise FileNotFoundError(f'Missing dataset at {DATASET_PATH}. Build it first (scrape -> analyze -> dataset_builder).')\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "print('Loaded:', DATASET_PATH)\n",
    "print('Shape:', df.shape)\n",
    "display(df.head())\n",
    "\n",
    "print('')\n",
    "print('Columns:')\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c7ec1",
   "metadata": {},
   "source": [
    "## 3) Choose target and task type\n",
    "Your current `dataset.csv` includes only metric columns. Pick one column as the label/target to learn.\n",
    "\n",
    "Common choices:\n",
    "- **Classification (binary):** `security_high` (or `security_medium`, `security_low`)\n",
    "- **Regression:** `maintainability_index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d1f30ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Configuration ----\n",
    "TARGET_COLUMN = 'y_binary'  # <- change me\n",
    "TASK = 'classification'  # 'classification' or 'regression'\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Basic validation\n",
    "if TARGET_COLUMN not in df.columns:\n",
    "    raise ValueError(f'TARGET_COLUMN={TARGET_COLUMN!r} not found. Available: {list(df.columns)}')\n",
    "if TASK not in {'classification', 'regression'}:\n",
    "    raise ValueError(\"TASK must be 'classification' or 'regression'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bb9b72",
   "metadata": {},
   "source": [
    "## 4) Build `X` and `y` (cleaning + split)\n",
    "This keeps only numeric features and fills missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486f8275",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target 'y_binary' is not numeric in the loaded dataset. Encode it to numbers (e.g., 0/1) or adjust preprocessing.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m numeric_df = df.select_dtypes(include=[np.number]).copy()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TARGET_COLUMN \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m numeric_df.columns:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m      7\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTarget \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTARGET_COLUMN\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m is not numeric in the loaded dataset. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      8\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEncode it to numbers (e.g., 0/1) or adjust preprocessing.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Drop rows with missing target\u001b[39;00m\n\u001b[32m     12\u001b[39m numeric_df = numeric_df.dropna(subset=[TARGET_COLUMN])\n",
      "\u001b[31mValueError\u001b[39m: Target 'y_binary' is not numeric in the loaded dataset. Encode it to numbers (e.g., 0/1) or adjust preprocessing."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keep numeric columns only (ExtraTrees in sklearn expects numeric input)\n",
    "numeric_df = df.select_dtypes(include=[np.number]).copy()\n",
    "if TARGET_COLUMN not in numeric_df.columns:\n",
    "    raise ValueError(\n",
    "        f'Target {TARGET_COLUMN!r} is not numeric in the loaded dataset. '\n",
    "        'Encode it to numbers (e.g., 0/1) or adjust preprocessing.'\n",
    "    )\n",
    "\n",
    "# Drop rows with missing target\n",
    "numeric_df = numeric_df.dropna(subset=[TARGET_COLUMN])\n",
    "\n",
    "y = numeric_df[TARGET_COLUMN]\n",
    "X = numeric_df.drop(columns=[TARGET_COLUMN])\n",
    "\n",
    "# Fill missing features with 0 (minimal, consistent default)\n",
    "X = X.fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE,\n",
    "    stratify=y if TASK == 'classification' and y.nunique() > 1 else None,\n",
    ")\n",
    "\n",
    "print('X_train:', X_train.shape, 'X_test:', X_test.shape)\n",
    "print('y distribution (train):')\n",
    "display(y_train.value_counts(dropna=False) if TASK == 'classification' else y_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299303b7",
   "metadata": {},
   "source": [
    "## 5) Train Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "\n",
    "if TASK == 'classification':\n",
    "    model = ExtraTreesClassifier(\n",
    "        n_estimators=400,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced_subsample',\n",
    "    )\n",
    "else:\n",
    "    model = ExtraTreesRegressor(\n",
    "        n_estimators=400,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('Trained:', model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb9534",
   "metadata": {},
   "source": [
    "## 6) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c377ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "if TASK == 'classification':\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('\\nClassification report:')\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "else:\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8089aa",
   "metadata": {},
   "source": [
    "## 7) Feature importance (quick look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec818269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fi = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "display(fi.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bc391",
   "metadata": {},
   "source": [
    "## 8) Save model + metadata\n",
    "This writes:\n",
    "- `models/extratrees_<task>_<target>.joblib`\n",
    "- `models/extratrees_<task>_<target>_features.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "safe_target = ''.join(c if c.isalnum() or c in ('_', '-') else '_' for c in TARGET_COLUMN)\n",
    "model_path = MODELS_DIR / f'extratrees_{TASK}_{safe_target}.joblib'\n",
    "features_path = MODELS_DIR / f'extratrees_{TASK}_{safe_target}_features.json'\n",
    "\n",
    "joblib.dump(model, model_path)\n",
    "features_path.write_text(json.dumps({\n",
    "    'target': TARGET_COLUMN,\n",
    "    'task': TASK,\n",
    "    'feature_columns': list(X.columns),\n",
    "    'random_state': RANDOM_STATE,\n",
    "}, indent=2))\n",
    "\n",
    "print('Saved model to:', model_path)\n",
    "print('Saved feature metadata to:', features_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd689c5",
   "metadata": {},
   "source": [
    "## 9) (Optional) Inference helper\n",
    "Given a single metrics record (dict), this predicts the target.\n",
    "\n",
    "Note: your inference input must have the **same feature columns** as training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(metrics_record: dict):\n",
    "    row = pd.DataFrame([metrics_record])\n",
    "    row = row.reindex(columns=X.columns, fill_value=0)\n",
    "    row = row.select_dtypes(include=[np.number]).fillna(0)\n",
    "    return model.predict(row)[0]\n",
    "\n",
    "# Example: take the first row of the dataset and predict\n",
    "example = X.iloc[0].to_dict()\n",
    "print('Prediction:', predict_one(example))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
