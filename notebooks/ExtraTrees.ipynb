{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4c8c66",
   "metadata": {},
   "source": [
    "# Extra Trees Model Training (from scraped GitHub code)\n",
    "\n",
    "This notebook trains an **Extra Trees** model on the metrics dataset produced by your pipeline.\n",
    "\n",
    "**Expected input:** `data/processed/dataset.csv` (built from analyzing code scraped from GitHub repos).\n",
    "\n",
    "**Output artifacts:** saved model + feature columns under `models/` (so you can reuse it for inference)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b88d54",
   "metadata": {},
   "source": [
    "## 1) Install dependencies (if needed)\n",
    "If you already have these installed, you can skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be689af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in a fresh environment, uncomment:\n",
    "%pip install -U pandas numpy scikit-learn joblib matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4755e",
   "metadata": {},
   "source": [
    "## 2) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41783a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /home/darth/the-duat/Notes/01_college/CSCI-417/project/data/processed/dataset_processed.csv\n",
      "Shape: (3088, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbreviation_density</th>\n",
       "      <th>average_cyclomatic_complexity</th>\n",
       "      <th>avg_line_length</th>\n",
       "      <th>comment_code_mismatch_score</th>\n",
       "      <th>comment_lines</th>\n",
       "      <th>comment_percentage</th>\n",
       "      <th>decision_density</th>\n",
       "      <th>documentation_coverage</th>\n",
       "      <th>external_vs_internal_field_access_ratio</th>\n",
       "      <th>functions</th>\n",
       "      <th>...</th>\n",
       "      <th>y_MisleadingComments</th>\n",
       "      <th>y_PoorDocumentation</th>\n",
       "      <th>y_UntestedCode</th>\n",
       "      <th>complexity_score</th>\n",
       "      <th>code_health</th>\n",
       "      <th>doc_quality</th>\n",
       "      <th>has_tests</th>\n",
       "      <th>coupling_complexity</th>\n",
       "      <th>smell_density</th>\n",
       "      <th>effort_impact_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.666324</td>\n",
       "      <td>0.568106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.623314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.718428</td>\n",
       "      <td>0.880992</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.150928</td>\n",
       "      <td>0.449420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.306982</td>\n",
       "      <td>0.531561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.326629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352370</td>\n",
       "      <td>0.932637</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.402474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.204312</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300120</td>\n",
       "      <td>0.929269</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.551215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.204312</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279220</td>\n",
       "      <td>0.932637</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.291447</td>\n",
       "      <td>0.019656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.204312</td>\n",
       "      <td>0.320598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279220</td>\n",
       "      <td>0.932637</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.272644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abbreviation_density  average_cyclomatic_complexity  avg_line_length  \\\n",
       "0                 0.000                       0.666324         0.568106   \n",
       "1                 0.000                       0.306982         0.531561   \n",
       "2                 0.333                       0.204312         0.348837   \n",
       "3                 0.500                       0.204312         0.325581   \n",
       "4                 0.500                       0.204312         0.320598   \n",
       "\n",
       "   comment_code_mismatch_score  comment_lines  comment_percentage  \\\n",
       "0                          0.0           1.00                 1.0   \n",
       "1                          0.0           0.25                 1.0   \n",
       "2                          0.0           0.00                 0.0   \n",
       "3                          0.0           0.00                 0.0   \n",
       "4                          0.0           0.00                 0.0   \n",
       "\n",
       "   decision_density  documentation_coverage  \\\n",
       "0          0.623314                     0.0   \n",
       "1          0.326629                     0.0   \n",
       "2          0.163200                     0.0   \n",
       "3          0.104000                     0.0   \n",
       "4          0.099429                     0.0   \n",
       "\n",
       "   external_vs_internal_field_access_ratio  functions  ...  \\\n",
       "0                                 0.458333     0.1250  ...   \n",
       "1                                 0.125000     0.0625  ...   \n",
       "2                                 0.041667     0.0000  ...   \n",
       "3                                 0.041667     0.0000  ...   \n",
       "4                                 0.041667     0.0000  ...   \n",
       "\n",
       "   y_MisleadingComments  y_PoorDocumentation  y_UntestedCode  \\\n",
       "0                   0.0                  1.0             1.0   \n",
       "1                   0.0                  1.0             0.0   \n",
       "2                   0.0                  1.0             0.0   \n",
       "3                   0.0                  1.0             0.0   \n",
       "4                   0.0                  1.0             0.0   \n",
       "\n",
       "   complexity_score  code_health  doc_quality  has_tests  coupling_complexity  \\\n",
       "0          0.718428     0.880992       0.4165          0             0.541667   \n",
       "1          0.352370     0.932637       0.4525          1             0.083333   \n",
       "2          0.300120     0.929269       0.5000          0             0.083333   \n",
       "3          0.279220     0.932637       0.5000          0             0.083333   \n",
       "4          0.279220     0.932637       0.5000          0             0.083333   \n",
       "\n",
       "   smell_density  effort_impact_ratio  \n",
       "0       0.150928             0.449420  \n",
       "1       0.402474             0.000000  \n",
       "2       0.551215             0.000000  \n",
       "3       0.291447             0.019656  \n",
       "4       0.272644             0.000000  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent  # notebooks/ -> repo root\n",
    "DATASET_PATH = PROJECT_ROOT / 'data' / 'processed' / 'dataset_processed.csv'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATASET_PATH.exists():\n",
    "    raise FileNotFoundError(f'Missing dataset at {DATASET_PATH}. Build it first (scrape -> analyze -> dataset_builder).')\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "print('Loaded:', DATASET_PATH)\n",
    "print('Shape:', df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bb9b72",
   "metadata": {},
   "source": [
    "## 4) Build `X` and `y` (cleaning + split)\n",
    "This keeps only numeric features and fills missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486f8275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2470, 42) X_test: (618, 42)\n",
      "Y distribution (train):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y_PoorDocumentation  y_UntestedCode  complexity_score  code_health  doc_quality  has_tests  coupling_complexity  smell_density  effort_impact_ratio\n",
       "0.0                  0.0             0.091123          0.932637     0.5          0          0.000000             0.000000       0.0                    196\n",
       "                                                                                 1          0.000000             0.000000       0.0                     86\n",
       "                                     0.195622          0.932637     0.5          0          0.083333             0.469554       0.0                     18\n",
       "                                                                                                                 0.422598       0.0                     10\n",
       "                                     0.279220          0.932637     0.5          0          0.166667             0.301856       0.0                      6\n",
       "                                                                                                                                                      ... \n",
       "1.0                  0.0             0.096557          0.929269     0.5          1          0.333333             0.098279       0.0                      1\n",
       "                                     0.096452          0.925901     0.5          1          0.250000             0.216717       0.0                      1\n",
       "                                                       0.922533     0.5          1          0.250000             0.277114       0.0                      1\n",
       "                                     0.096348          0.925901     0.5          1          0.333333             0.176083       0.0                      1\n",
       "                                     0.098960          0.874256     0.5          1          0.250000             0.123087       0.0                      1\n",
       "Name: count, Length: 2048, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keep numeric columns only (ExtraTrees in sklearn expects numeric input)\n",
    "numeric_df = df.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# Drop rows with missing target\n",
    "numeric_df = numeric_df.dropna(subset=[x for x in numeric_df.columns if x.startswith('y_')])\n",
    "\n",
    "Y = numeric_df.iloc[:, 39:53]\n",
    "X = numeric_df.drop(columns=[x for x in numeric_df.columns if x.startswith('y_')])\n",
    "\n",
    "# Fill missing features with 0 (minimal, consistent default)\n",
    "X = X.fillna(0)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=1042\n",
    ")\n",
    "\n",
    "print('X_train:', X_train.shape, 'X_test:', X_test.shape)\n",
    "print('Y distribution (train):')\n",
    "display(Y_train.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299303b7",
   "metadata": {},
   "source": [
    "## 5) Train Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffc7b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: MultiOutputRegressor\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "\n",
    "RANDOM_STATE = 10\n",
    "est_params = dict(n_estimators=400, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "def _is_binary_series(s):\n",
    "    vals = np.unique(s.dropna())\n",
    "    return set(vals.tolist()) <= {0, 1}\n",
    "\n",
    "# Choose classifier vs regressor (and multioutput wrappers) based on Y_train\n",
    "if Y_train.shape[1] == 1:\n",
    "    y = Y_train.iloc[:, 0]\n",
    "    if pd.api.types.is_integer_dtype(y) or _is_binary_series(y):\n",
    "        model = ExtraTreesClassifier(**est_params, class_weight='balanced_subsample')\n",
    "    else:\n",
    "        model = ExtraTreesRegressor(**est_params)\n",
    "else:\n",
    "    # Multi-output: use classifier only if all targets are binary {0,1}\n",
    "    all_binary = all(_is_binary_series(Y_train[c]) for c in Y_train.columns)\n",
    "    if all_binary:\n",
    "        base = ExtraTreesClassifier(**est_params, class_weight='balanced_subsample')\n",
    "        model = MultiOutputClassifier(base)\n",
    "    else:\n",
    "        base = ExtraTreesRegressor(**est_params)\n",
    "        model = MultiOutputRegressor(base)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "print('Trained:', model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb9534",
   "metadata": {},
   "source": [
    "## 6) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0c377ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-output evaluation (9 targets):\n",
      "  Overall accuracy (element-wise): 0.4266\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m  Overall accuracy (element-wise): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Y_test.columns):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     col_acc = \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m  Target \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_absolute_error(Y_test,\u001b[38;5;250m \u001b[39mY_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/the-duat/Notes/01_college/CSCI-417/project/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/the-duat/Notes/01_college/CSCI-417/project/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:411\u001b[39m, in \u001b[36maccuracy_score\u001b[39m\u001b[34m(y_true, y_pred, normalize, sample_weight)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[32m    410\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m y_type, y_true, y_pred, sample_weight = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type.startswith(\u001b[33m\"\u001b[39m\u001b[33mmultilabel\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    416\u001b[39m     differing_labels = _count_nonzero(y_true - y_pred, xp=xp, device=device, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/the-duat/Notes/01_college/CSCI-417/project/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:127\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred, sample_weight)\u001b[39m\n\u001b[32m    124\u001b[39m     y_type = {\u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    128\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mClassification metrics can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m targets\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    129\u001b[39m             type_true, type_pred\n\u001b[32m    130\u001b[39m         )\n\u001b[32m    131\u001b[39m     )\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[32m    134\u001b[39m y_type = y_type.pop()\n",
      "\u001b[31mValueError\u001b[39m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, mean_absolute_error, mean_squared_error, r2_score,\n",
    ")\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# For multi-output: evaluate per-column accuracy and overall metrics\n",
    "if Y_test.shape[1] > 1:\n",
    "    print(f'Multi-output evaluation ({Y_test.shape[1]} targets):')\n",
    "    overall_acc = (Y_pred == Y_test.values).mean()  # Element-wise accuracy\n",
    "    print(f'  Overall accuracy (element-wise): {overall_acc:.4f}')\n",
    "    \n",
    "    for i, col in enumerate(Y_test.columns):\n",
    "        col_acc = accuracy_score(Y_test.iloc[:, i], Y_pred[:, i])\n",
    "        print(f'  Target \"{col}\": {col_acc:.4f}')\n",
    "    \n",
    "    print(f'\\n  MAE: {mean_absolute_error(Y_test, Y_pred):.4f}')\n",
    "    print(f'  MSE: {mean_squared_error(Y_test, Y_pred):.4f}')\n",
    "else:\n",
    "    # Single output: standard metrics\n",
    "    y_test_col = Y_test.iloc[:, 0]\n",
    "    y_pred_col = Y_pred[:, 0] if Y_pred.ndim > 1 else Y_pred\n",
    "    \n",
    "    print(f'Accuracy: {accuracy_score(y_test_col, y_pred_col):.4f}')\n",
    "    print(f'MAE: {mean_absolute_error(y_test_col, y_pred_col):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8089aa",
   "metadata": {},
   "source": [
    "## 7) Feature importance (quick look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec818269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fi = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "display(fi.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bc391",
   "metadata": {},
   "source": [
    "## 8) Save model + metadata\n",
    "This writes:\n",
    "- `models/extratrees_<task>_<target>.joblib`\n",
    "- `models/extratrees_<task>_<target>_features.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "safe_target = ''.join(c if c.isalnum() or c in ('_', '-') else '_' for c in TARGET_COLUMN)\n",
    "model_path = MODELS_DIR / f'extratrees_{TASK}_{safe_target}.joblib'\n",
    "features_path = MODELS_DIR / f'extratrees_{TASK}_{safe_target}_features.json'\n",
    "\n",
    "joblib.dump(model, model_path)\n",
    "features_path.write_text(json.dumps({\n",
    "    'target': TARGET_COLUMN,\n",
    "    'task': TASK,\n",
    "    'feature_columns': list(X.columns),\n",
    "    'random_state': RANDOM_STATE,\n",
    "}, indent=2))\n",
    "\n",
    "print('Saved model to:', model_path)\n",
    "print('Saved feature metadata to:', features_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd689c5",
   "metadata": {},
   "source": [
    "## 9) (Optional) Inference helper\n",
    "Given a single metrics record (dict), this predicts the target.\n",
    "\n",
    "Note: your inference input must have the **same feature columns** as training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(metrics_record: dict):\n",
    "    row = pd.DataFrame([metrics_record])\n",
    "    row = row.reindex(columns=X.columns, fill_value=0)\n",
    "    row = row.select_dtypes(include=[np.number]).fillna(0)\n",
    "    return model.predict(row)[0]\n",
    "\n",
    "# Example: take the first row of the dataset and predict\n",
    "example = X.iloc[0].to_dict()\n",
    "print('Prediction:', predict_one(example))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
