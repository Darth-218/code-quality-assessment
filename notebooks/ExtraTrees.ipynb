{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4c8c66",
   "metadata": {},
   "source": [
    "# Extra Trees Model Training (from scraped GitHub code)\n",
    "\n",
    "This notebook trains an **Extra Trees** model on the metrics dataset produced by your pipeline.\n",
    "\n",
    "**Expected input:** `data/processed/dataset.csv` (built from analyzing code scraped from GitHub repos).\n",
    "\n",
    "**Output artifacts:** saved model + feature columns under `models/` (so you can reuse it for inference)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b88d54",
   "metadata": {},
   "source": [
    "## 1) Install dependencies (if needed)\n",
    "If you already have these installed, you can skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be689af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.4.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.8.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.8-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/omarh/Documents/GitHub/code-quality-assessment/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Using cached scipy-1.16.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.61.1-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/omarh/Documents/GitHub/code-quality-assessment/.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-12.0.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/omarh/Documents/GitHub/code-quality-assessment/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.3-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.3 MB)\n",
      "Downloading numpy-2.4.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m952.5 kB/s\u001b[0m  \u001b[33m0:00:17\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached scikit_learn-1.8.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached matplotlib-3.10.8-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.61.1-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "Using cached kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached pillow-12.0.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached scipy-1.16.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, cycler, scipy, pandas, contourpy, scikit-learn, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [matplotlib]5\u001b[0m [matplotlib]n]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 joblib-1.5.3 kiwisolver-1.4.9 matplotlib-3.10.8 numpy-2.4.0 pandas-2.3.3 pillow-12.0.0 pyparsing-3.3.1 pytz-2025.2 scikit-learn-1.8.0 scipy-1.16.3 threadpoolctl-3.6.0 tzdata-2025.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If running in a fresh environment, uncomment:\n",
    "%pip install -U pandas numpy scikit-learn joblib matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4755e",
   "metadata": {},
   "source": [
    "## 2) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41783a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent  # notebooks/ -> repo root\n",
    "DATASET_PATH = PROJECT_ROOT / 'data' / 'processed' / 'dataset.csv'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATASET_PATH.exists():\n",
    "    raise FileNotFoundError(f'Missing dataset at {DATASET_PATH}. Build it first (scrape -> analyze -> dataset_builder).')\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "print('Loaded:', DATASET_PATH)\n",
    "print('Shape:', df.shape)\n",
    "display(df.head())\n",
    "\n",
    "print('')\n",
    "print('Columns:')\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c7ec1",
   "metadata": {},
   "source": [
    "## 3) Choose target and task type\n",
    "Your current `dataset.csv` includes only metric columns. Pick one column as the label/target to learn.\n",
    "\n",
    "Common choices:\n",
    "- **Classification (binary):** `security_high` (or `security_medium`, `security_low`)\n",
    "- **Regression:** `maintainability_index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f30ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Configuration ----\n",
    "TARGET_COLUMN = 'security_high'  # <- change me\n",
    "TASK = 'classification'  # 'classification' or 'regression'\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Basic validation\n",
    "if TARGET_COLUMN not in df.columns:\n",
    "    raise ValueError(f'TARGET_COLUMN={TARGET_COLUMN!r} not found. Available: {list(df.columns)}')\n",
    "if TASK not in {'classification', 'regression'}:\n",
    "    raise ValueError(\"TASK must be 'classification' or 'regression'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bb9b72",
   "metadata": {},
   "source": [
    "## 4) Build `X` and `y` (cleaning + split)\n",
    "This keeps only numeric features and fills missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keep numeric columns only (ExtraTrees in sklearn expects numeric input)\n",
    "numeric_df = df.select_dtypes(include=[np.number]).copy()\n",
    "if TARGET_COLUMN not in numeric_df.columns:\n",
    "    raise ValueError(\n",
    "        f'Target {TARGET_COLUMN!r} is not numeric in the loaded dataset. '\n",
    "        'Encode it to numbers (e.g., 0/1) or adjust preprocessing.'\n",
    "    )\n",
    "\n",
    "# Drop rows with missing target\n",
    "numeric_df = numeric_df.dropna(subset=[TARGET_COLUMN])\n",
    "\n",
    "y = numeric_df[TARGET_COLUMN]\n",
    "X = numeric_df.drop(columns=[TARGET_COLUMN])\n",
    "\n",
    "# Fill missing features with 0 (minimal, consistent default)\n",
    "X = X.fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE,\n",
    "    stratify=y if TASK == 'classification' and y.nunique() > 1 else None,\n",
    ")\n",
    "\n",
    "print('X_train:', X_train.shape, 'X_test:', X_test.shape)\n",
    "print('y distribution (train):')\n",
    "display(y_train.value_counts(dropna=False) if TASK == 'classification' else y_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299303b7",
   "metadata": {},
   "source": [
    "## 5) Train Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "\n",
    "if TASK == 'classification':\n",
    "    model = ExtraTreesClassifier(\n",
    "        n_estimators=400,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced_subsample',\n",
    "    )\n",
    "else:\n",
    "    model = ExtraTreesRegressor(\n",
    "        n_estimators=400,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('Trained:', model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb9534",
   "metadata": {},
   "source": [
    "## 6) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c377ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "if TASK == 'classification':\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('\\nClassification report:')\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "else:\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8089aa",
   "metadata": {},
   "source": [
    "## 7) Feature importance (quick look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec818269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fi = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "display(fi.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bc391",
   "metadata": {},
   "source": [
    "## 8) Save model + metadata\n",
    "This writes:\n",
    "- `models/extratrees_<task>_<target>.joblib`\n",
    "- `models/extratrees_<task>_<target>_features.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "safe_target = ''.join(c if c.isalnum() or c in ('_', '-') else '_' for c in TARGET_COLUMN)\n",
    "model_path = MODELS_DIR / f'extratrees_{TASK}_{safe_target}.joblib'\n",
    "features_path = MODELS_DIR / f'extratrees_{TASK}_{safe_target}_features.json'\n",
    "\n",
    "joblib.dump(model, model_path)\n",
    "features_path.write_text(json.dumps({\n",
    "    'target': TARGET_COLUMN,\n",
    "    'task': TASK,\n",
    "    'feature_columns': list(X.columns),\n",
    "    'random_state': RANDOM_STATE,\n",
    "}, indent=2))\n",
    "\n",
    "print('Saved model to:', model_path)\n",
    "print('Saved feature metadata to:', features_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd689c5",
   "metadata": {},
   "source": [
    "## 9) (Optional) Inference helper\n",
    "Given a single metrics record (dict), this predicts the target.\n",
    "\n",
    "Note: your inference input must have the **same feature columns** as training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(metrics_record: dict):\n",
    "    row = pd.DataFrame([metrics_record])\n",
    "    row = row.reindex(columns=X.columns, fill_value=0)\n",
    "    row = row.select_dtypes(include=[np.number]).fillna(0)\n",
    "    return model.predict(row)[0]\n",
    "\n",
    "# Example: take the first row of the dataset and predict\n",
    "example = X.iloc[0].to_dict()\n",
    "print('Prediction:', predict_one(example))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
